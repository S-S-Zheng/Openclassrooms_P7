{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec21e2e",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:1.5em;font-weight:bold;background-color:yellow\">Partie 1 - Importer les données et explorer les radiographies</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48945850",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:1.2em;font-weight:bold\">Mise en place</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module pour recharger un module sans redemarrer le kernel\n",
    "# import importlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# On utilise pytorch ici plutot que tensorflow\n",
    "# Avantage: plus personnalisable VS Plus facile a utiliser \n",
    "# Définit les tenseurs, couches de neurones et algo d'opti (SGD,Adam)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Pour créer une structure pour lire les images et les envoyer par paquet (batches) au GPU\n",
    "from torch.utils.data import DataLoader\n",
    "# Contient des architectures pré-entraînées (ResNet, VGG).\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sert à éviter les Warnings avec les transformations sur des vues en transformant \n",
    "# ces warning en erreur obligeant ainsi à ne travailler que sur des copies ou les originaux.\n",
    "\n",
    "pd.set_option('mode.chained_assignment','raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoute le dossier datas_manipulation au sys.path. Remarque ne pas oublier le __init__.py dans le dossier datas_manipulation\n",
    "import sys\n",
    "# root_path = Path(__file__).resolve().parents[1] # Ne fonctionne pas sur notebook\n",
    "ROOT_PATH = Path.cwd().parent\n",
    "sys.path.append(str(ROOT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63353f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions personnelles\n",
    "\n",
    "from notebooks.utils.dataset import BaseTransform, ImagesToDataset\n",
    "from notebooks.utils.models import FeatureExtractor, BrainCancerClassifier\n",
    "from notebooks.utils.analysis import ClusterManager\n",
    "from notebooks.utils.training import Trainer, SslManager\n",
    "from notebooks.utils.plotting.make_model_plots import plot_clustering\n",
    "from notebooks.utils.data_manipulation import save_datas, combinaisonAB\n",
    "from notebooks.utils.plotting.config_figures import save_figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables/paramètres globales\n",
    "\n",
    "# Création dossier results\n",
    "SAVE_PATH = ROOT_PATH.joinpath('datas/results')\n",
    "Path.mkdir(SAVE_PATH,exist_ok = True)\n",
    "\n",
    "# Pour la reproductibilité (similaire a random_state) \n",
    "# --> influence l'initialisation des poids ResNet et le mélange du DataLoader\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config pour basculer sur le GPU si possible (50x plus rapide en deep learning que CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "# Taille des paquets (en puissance de 2 pour s'aligner avec l'archi GPU: 2 4 8 16 32 64)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Config des images\n",
    "IMG_SIZE = 224 # Résolution standard \n",
    "# Cas transfer learning avec ResNet: Les valeurs données sont les moyennes et ecarts type des \n",
    "# couleurs RGB dans ImageNet\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "RANDOM_STATE=42\n",
    "N_JOBS=-1\n",
    "N_FEATURES = 512 # Nombre de features issu des CNN,en 18,34 couches on a 512 features, \n",
    "# en 50,101 et 152 on passe a 2048 features, avec VGG16 on est 4096 \n",
    "# et pour EfficientNet-BO c'est 1280 features\n",
    "TEST_SIZE = 0.2\n",
    "N_EPOCH = 10\n",
    "EXPERIMENT_NAME = \"experiment_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de la confinguration globale du projet\n",
    "project_config = {\n",
    "    \"model\":\"resnet34\",\n",
    "    \"n_features\":N_FEATURES,\n",
    "    \"n_jobs\":N_JOBS,\n",
    "    \"batch\":BATCH_SIZE,\n",
    "    \"device\":str(DEVICE),\n",
    "    \"img_size\":IMG_SIZE,\n",
    "    \"img_mean\":IMG_MEAN,\n",
    "    \"img_std\":IMG_STD,\n",
    "    \"test_size\":TEST_SIZE,\n",
    "    \"random_state\":RANDOM_STATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin des données brutes\n",
    "DATAS_PATH = ROOT_PATH/\"datas/raw/mri_dataset_brain_cancer_oc\"\n",
    "\n",
    "# Listing des fichiers qui composent les labellisés des non labellisés\n",
    "# glob pour les fichiers et rglob si il y a des sous-dossiers\n",
    "avec_labels_path = list((DATAS_PATH / \"avec_labels\").rglob(\"*.jpg\"))\n",
    "sans_label_path = list((DATAS_PATH / \"sans_label\").glob(\"*.jpg\"))\n",
    "project_config.update({\"avec_label\":len(avec_labels_path),\"sans_label\":len(sans_label_path)})\n",
    "\n",
    "# Encodage des labels (0: normal, 1: cancer, -1: sans_label)\n",
    "avec_labels_encoding = [1 if \"cancer\" in path.parts else 0 for path in avec_labels_path]\n",
    "all_paths = avec_labels_path + sans_label_path\n",
    "all_labels = avec_labels_encoding + ([-1] * len(sans_label_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de quelques exemples\n",
    "path_samples = [avec_labels_path[0], avec_labels_path[50], sans_label_path[0]]\n",
    "label_samples = [\"cancer\",\"sain\",\"inconnu\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(path_samples), figsize=(15, 3))\n",
    "for i,(path,label) in enumerate(zip(path_samples,label_samples)):\n",
    "    image = Image.open(path)\n",
    "    # L'image est un tensor, on le convertit en numpy array et on le transpose pour l'affichage\n",
    "    # On dénormalise aussi l'image pour un affichage correct\n",
    "    # img = image.numpy().transpose(1, 2, 0) * 0.5 + 0.5\n",
    "    # axes[i].imshow(img.squeeze(), cmap='gray') # Use cmap='gray' for single channel images if needed\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {label}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=============== Contenu du dataset ================\")\n",
    "with open(\n",
    "    DATAS_PATH/\"Jeu de Données d'Images Cérébrales pour la Détection de Tumeurs.txt\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43fe6b",
   "metadata": {},
   "source": [
    "Le zip \"**mri_dataset_brain_cancer_oc**\" contient deux dossiers et un fichier texte qui résume le contenu du dataset:\n",
    "- **sans_label/**: 1406 images non étiquetées\n",
    "- **avec_labels/**: 100 images étiquetées\n",
    "\n",
    "Dans le dossier avec label on trouve deux sous-dossiers:\n",
    "- **Normal/** : 50 images de cerveaux sains.\n",
    "- **Cancer/** : 50 images de cerveaux présentant des signes de tumeurs.\n",
    "\n",
    "**Caractéristiques des images**\n",
    "\n",
    "- Toutes les images ont été redimensionnées à une taille standardisée de 512×512 pixels. \n",
    "- Elles sont enregistrées au format d'image courant JPEG (.jpg).\n",
    "- Poids moyen autour de 20 Ko\n",
    "- Nomination hashé\n",
    "- Noir et blanc\n",
    "- Qualité des images variable (floue, saturée ...)\n",
    "- Coupes variables (dessus, de face, de profil) avec prédominance des coupes du dessus (ou dessous?)\n",
    "- Certaines images ont des cadres, des echelles, des caractéristiques d'imagerie (W,L, n°)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e312e70",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:1.5em;font-weight:bold;background-color:yellow\">Partie 2 - Pré-traitement et extraction des features</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d1415",
   "metadata": {},
   "source": [
    "Comme nous l'avions relevé, les images nécéssitent un pré traitement afin de pouvoir être utilisable. Elles ont la même structure externe (pixels, format, poids, nomination) mais leur contenu doit aussi être standardiser:\n",
    "- normaliser la nuance de gris\n",
    "- enlever les informations d'image dans les images (W,L,n°) ($\\approx$ data leaking)\n",
    "Une fois celà fait, il restera à transformer les images en données exploitable à savoir l'embedding visuel via ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aade4c",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:1.2em;font-weight:bold\">Préparation et embedding</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ef94f",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold\"> *Remarque personnelle*: Il est interessant de s'appercevoir que Pytorch pousse à travailler au travers de subclass</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chemin des données brutes\n",
    "# DATAS_PATH = ROOT_PATH/\"datas/raw/mri_dataset_brain_cancer_oc\"\n",
    "\n",
    "# # Listing des fichiers qui composent les labellisés des non labellisés\n",
    "# # glob pour les fichiers et rglob si il y a des sous-dossiers\n",
    "# avec_labels_path = list((DATAS_PATH / \"avec_labels\").rglob(\"*.jpg\"))\n",
    "# sans_label_path = list((DATAS_PATH / \"sans_label\").glob(\"*.jpg\"))\n",
    "\n",
    "# # Encodage des labels (0: normal, 1: cancer, -1: sans_label)\n",
    "# avec_labels_encoding = [1 if \"cancer\" in path.parts else 0 for path in avec_labels_path]\n",
    "# all_paths = avec_labels_path + sans_label_path\n",
    "# all_labels = avec_labels_encoding + ([-1] * len(sans_label_path))\n",
    "\n",
    "# ================= Nettoyage ========================\n",
    "# plt.close()\n",
    "del (\n",
    "    #avec_labels_path, sans_label_path, avec_labels_encoding, # Réutilisés dans en supervisé\n",
    "    path_samples,label_samples,image,fig,axes\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ff5d1",
   "metadata": {},
   "source": [
    "<span style=\"color:purple;font-weight:bold\">Extraction des features via ResNet</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbafc2",
   "metadata": {},
   "source": [
    "Comme toujours, il est nécéssaire d'avoir des informations compréhensibles pour une machine pour qu'un modèle puisse performer (ce n'est donc pas le cas des images). Pour cela on va donc pré-traiter les images afin qu'elles partent d'une base commune (redimensionnement et normalisation).\n",
    "\n",
    "On va ensuite utiliser un CNN (ResNet18 par exemple) auquel on retire la dernière couche (couche de classification) afin d'obtenir un extracteur de features et on fait passer toutes les images pour constituer un tableau dont les lignes représentent les images et les colonnes, les caractéristiques de ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1399c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des images\n",
    "# Instanciation du pré traitement\n",
    "transform = BaseTransform(mean=IMG_MEAN,std=IMG_STD,size=IMG_SIZE).preproc(train=False)\n",
    "# Génration du dataset SANS les augmentations (train et test encore mélangé pour le moment)\n",
    "full_dataset = ImagesToDataset(all_paths, all_labels, transform=transform)\n",
    "# Génération du loader qui va fournir la donnée au GPU par batch\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Instanciation du modèle d'extraction des caractéristiques\n",
    "# to(DEVICE) déplace les poids du modèle de la RAM/CPU vers la VRAM/GPU\n",
    "extractor = FeatureExtractor(pretrained=True,model_name=project_config['model']).to(DEVICE)\n",
    "# Rend le comportement de certaines couches déterministes ==> indispensable pour l'embedding\n",
    "extractor.eval()\n",
    "\n",
    "# Extraction\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Par défaut, Pytorch mémorise chaque calcul pour faire la retropropagation de gradient\n",
    "# indispensable si entrainement or ici on souhaite juste lire, on desactive donc la mémoire.\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in full_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        features = extractor(images) # (Batch, N_FEATURES)\n",
    "        features_list.extend(features.cpu().numpy()) # GPU --> CPU + tenseurs --> tableau numpy\n",
    "        labels_list.extend(labels.cpu().tolist())\n",
    "\n",
    "# Mise sous forme de df\n",
    "cols = [f\"feature_{i}\" for i in range(N_FEATURES)]\n",
    "df_features = pd.DataFrame(features_list, columns=cols)\n",
    "df_features['label'] = labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8953eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Nettoyage et sauvegarde ========================\n",
    "del full_dataset, full_loader, images, features, features_list, labels_list, cols\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# if not (SAVE_PATH/\"df_features/df_features_no_supervised.csv\").exists():\n",
    "save_datas(\n",
    "    df_features,\n",
    "    SAVE_PATH/\"unsupervised\"/EXPERIMENT_NAME,\n",
    "    filename=\"df_features\",\n",
    "    format=\"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df9472",
   "metadata": {},
   "source": [
    "**Remarque**: Le gèle des couches convolutionnelles s'est faite en utilisant .eval() et .no_grad().\n",
    "- eval() agit sur certaines couches comme le batch normalization qui a un comportement aléatoire afin de les rendre déterministe.\n",
    "- no_grad() désactive la mémorisation de Pytorch ce qui l'empêche d'apprendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771d7c9",
   "metadata": {},
   "source": [
    "On a un df avec les 100 premiers elements les fortements labellisés: les 50 premiers sont les cancereux, les 50 suivants les sains et les 1406 après les inconnus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14962a9",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:1.5em;font-weight:bold;background-color:yellow\">Partie 3 - Analyse non supervisée</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb3f4f",
   "metadata": {},
   "source": [
    "Le but à cete étape est de confirmer que le CNN amputé employé est capable de caractériser correctement les images.\n",
    "\n",
    "Pour cela on va on test le tableau de features obtenu, on utilise pour cela un reducteur de dimension et un cluster.\n",
    "1. Le modèle de réduction de dimension va condenser l'information issu de l'ensemble des features en n_components qui vont servir de coordonnées spatiale.\n",
    "    - Le PCA est une méthode linéaire qui cherche à faire pivoter les données pour trouver les axes de plus grande variance.\n",
    "    - Le t-SNE est non-linéaire et cherche à conserver la structure locale (les voisins proches).\n",
    "2. Le modèle de clustering va procéder au regroupement des images en cluster (groupe/classe...) en cohérance avec les informations des images.\n",
    "    - KMeans divise l'espace en \"cellules\" autour de centres (centroïdes).\n",
    "    - DBSCAN regarde si les points sont \"serrés\".\n",
    "\n",
    "A la fin de ce process, on juge suivant l'ARI qui va valider la qualité des embeddings:\n",
    "- Si le CNN (ResNet18 par exemple) est bon, les features extraites devraient avoir formé des lignes (caract des images) dont les tenseurs sont similaires suivant qui soient d'une classe ou de l'autre (sain/cancer).\n",
    "- Si le clustering (KMeans ou DBSCAN) a regroupé correctement les images (score ARI -> 1) alors l'extraction de feature est validée, l'extracteur est utilisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56744e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gestionnaire de sauvegarde\n",
    "unsupervised_manager = SslManager(\n",
    "    EXPERIMENT_NAME,\n",
    "    root_path=SAVE_PATH,\n",
    "    extension_path=\"unsupervised\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaires des hyperparamètres des modèles\n",
    "# Réduction de dimension\n",
    "pca_dict = {\n",
    "    \"n_components\": 50, # Nombre de dimensions finales. \n",
    "    # rq: si entre 0 et 1, on demande une proportion d'information a conserver\n",
    "}\n",
    "tsne_dict= {\n",
    "    \"n_components\": 2, \n",
    "    \"random_state\": RANDOM_STATE, \n",
    "    \"init\": 'pca', #Comment placer les points au départ. 'pca' est plus stable que 'random'\n",
    "    \"learning_rate\": 'auto',\n",
    "    \"n_jobs\":N_JOBS\n",
    "}\n",
    "# umap_dict = {\n",
    "#     \"n_neighbors\":15, # définit taille du voisinnage (entre 2-10 faible):focus sur la structure locale\n",
    "#     # (entre 30-100 fort): focus sur la structure globale \n",
    "#     \"min_dist\":0.1, # densité des clusters (0.001-0.05 faible) compacte les clusters,\n",
    "#     # (entre 0.2 a 0.5 fort): points plus étalé pour voir la topologie générale\n",
    "#     \"n_components\":2,\n",
    "#     \"metric\":\"cosine\", # méthdoe de calcul des distances\n",
    "# }\n",
    "\n",
    "# Clustering\n",
    "kmeans_dict = {\n",
    "    \"n_clusters\": 2, #Le nombre de groupes imposé.\n",
    "    \"random_state\": RANDOM_STATE, \n",
    "    \"n_init\": 10,\n",
    "    # init : \"k-means++\", # Placement intelligent, Centroides loin les uns des autres au départ.\n",
    "    # max_iter: 300,\n",
    "}\n",
    "dbscan_dict = {\n",
    "    \"eps\": 1.0, # Distance max pour que deux points == \"voisins\". Très sensible. défaut 0.5\n",
    "    \"min_samples\": 5, # Nb min de points pour former un groupe. Si <5, tout devient un cluster\n",
    "    # metric : \"euclidean\", # Regle de calcul des distance\n",
    "    # algorithm : \"auto\", # Méthode de recherche des voisins\n",
    "    # leaf_size : 30, # lié a algorithm \"ball_tree\". Impacte la vitesse\n",
    "    \"n_jobs\" : N_JOBS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des hyperparamètres utilisés en non supervisée\n",
    "\n",
    "unsupervised_config = project_config | {\n",
    "    **pca_dict, \n",
    "    **tsne_dict, \n",
    "    # **umap_dict, \n",
    "    **kmeans_dict, \n",
    "    **dbscan_dict\n",
    "}\n",
    "\n",
    "unsupervised_manager.save_config(unsupervised_config)\n",
    "\n",
    "# ================== Nettoyage =================\n",
    "del unsupervised_config\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour regrouper les nom des algo et les dictionnaires d'hyperparams\n",
    "red_dict = {\"pca\":pca_dict,\"tsne\":tsne_dict} \n",
    "# probleme de dépence revoir plus tard pour ,\"umap\":umap_dict}\n",
    "clust_dict = {\"kmeans\":kmeans_dict,\"dbscan\":dbscan_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ead80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du Manager\n",
    "analyzer = ClusterManager(df_features)\n",
    "\n",
    "\n",
    "unsupervised_metrics = []\n",
    "for red_key,red_value in red_dict.items():\n",
    "    # ========= REDUCTION DE DIMENSION ==============\n",
    "    reduction_dim = analyzer.reduce_dimensions(red_key,red_value) #type:ignore\n",
    "\n",
    "    for clust_key,clust_value in clust_dict.items():\n",
    "        # =========== CLUSTERING =====================\n",
    "        df_cluster = analyzer.apply_clustering(red_key,clust_key,clust_value) #type:ignore\n",
    "        \n",
    "        # ========== EVALUATION DES SCORES ============\n",
    "        # ARI (nécessite true_labels)\n",
    "        ari_score = analyzer.evaluate_ari(f\"cluster_{red_key}_{clust_key}\")\n",
    "        # Silhouette (compare les distances de clustering avec les distances init df_features)\n",
    "        silhouette_score = analyzer.evaluate_silhouette(\n",
    "            # df_feature=df_features,\n",
    "            # method=f'cluster_{red_key}_{clust_key}'\n",
    "            red_key,clust_key\n",
    "        )\n",
    "        \n",
    "        # ======== SAUVEGARDE INDIVIDUELLE ================\n",
    "        temp_metrics ={\n",
    "            \"reduction\" : red_key,\n",
    "            \"algo\" : clust_key,\n",
    "            \"ari\" : ari_score,\n",
    "            \"silhouette\" : silhouette_score\n",
    "        }\n",
    "        # Metriques\n",
    "        unsupervised_manager.log_metrics(temp_metrics)\n",
    "        unsupervised_metrics.append(temp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a13dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= SAUVEGARDE ET AFFICHAGE DES RESULTATS ======================\n",
    "save_datas(\n",
    "    df_cluster,\n",
    "    SAVE_PATH/\"unsupervised\"/EXPERIMENT_NAME,\n",
    "    filename=\"df_cluster\",\n",
    "    format =\"parquet\"\n",
    ")\n",
    "\n",
    "fig_cluster = plot_clustering(df_cluster, reduction_dim)\n",
    "save_figure(\n",
    "    f\"plot_unsupervised_{EXPERIMENT_NAME}\",\n",
    "    SAVE_PATH/\"figures\"\n",
    ")#, unsupervised_manager.root_path / \"figures\")\n",
    "\n",
    "pd.DataFrame(unsupervised_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de71670",
   "metadata": {},
   "source": [
    "- Les scores ARI sont faibles avec KMeans et de 0 avec DBSCAN donc les algorithmes de regroupement distinguent difficile une image cancereuse d'une image saine (et même pas du tout pour DBSCAN), elle range aléatoirement.\n",
    "- **Le clustering (modèle non-supervisé) sur les features brutes du ResNet ne permet pas de distinguer les classes. Les labels faibles générés sont donc peu fiables et un entraînement supervisé est indispensable**\n",
    "\n",
    "Ce résultat était probable car le ResNet est un CNN pré-entrainé sur ImageNet qui contient plus de 14 millions d'images haute résolution de 224 pixels sur divers catégories (plus de 1000) allant des animmaux, aux vehicules en passant pour des sous-catégories... Cependant il est probable que le cas particulier des radiographies, plus spécifiquement sur le cancer encéphalite est absent du jeu couplé aux qualité d'image variable et autres bruits, il en découle ainsi que ResNet reconnait dans les très grandes lignes (une tête, un humain?) mais est incapable de faire la distinction même partielle d'un cerveau sain VS cerveau avec un cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Nettoyage =================\n",
    "del (df_features, df_cluster, reduction_dim,\n",
    "    analyzer, unsupervised_manager,\n",
    "    temp_metrics\n",
    ")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476babf",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:1.5em;font-weight:bold;background-color:yellow\">Partie 4 - Appliquer la méthode supervisée</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559dfb4",
   "metadata": {},
   "source": [
    "La méthode supervisée revient à faire de la classification en guidant le modèle via les images labellisées, donc on a besoin d'un set regroupant les valeurs des features X et un set de target y. On ne peut pas repartir de *df_features* car c'était la df \"échouée\" de l'extracteur de base ResNet, de plus, le jeu ne comportait pas d'augmentation sur la partie à entrainer et était composé du jeu entier (labellisés et non labellisés), il faut donc remonter plus haut à savoir les images brutes labellisées et pour cela on va passer par les loaders qui vont se charger de fournir les batch d'image à partir de leur chemin:\n",
    "- X sera donc composé des chemins des images (Series!) et y sera formé par les labels.\n",
    "- On se constitue un jeu d'entrainement augmenté et un jeu de validation\n",
    "- On créé les loaders\n",
    "- On entraine le modèle en relevant les métriques d'intérêt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d26abd",
   "metadata": {},
   "source": [
    "<span style=\"color:purple;font-weight:bold\">Entrainement supervisé</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f71661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gestionnaire de sauvegarde\n",
    "supervised_manager = SslManager(\n",
    "    EXPERIMENT_NAME,\n",
    "    root_path=SAVE_PATH,\n",
    "    extension_path=\"supervised\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_config = project_config | {\n",
    "    \"num_classes\":1,\n",
    "    \"supervised_n_epoch\":N_EPOCH*3,\n",
    "    \"supervised_learning_rate\":1e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# juste par confort\n",
    "X = avec_labels_path\n",
    "y = avec_labels_encoding\n",
    "\n",
    "# Train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets & Loaders\n",
    "\n",
    "# Instanciation de l'objet de redim, norm, augmentation\n",
    "base_transform = BaseTransform(mean=IMG_MEAN,std=IMG_STD,size=IMG_SIZE)\n",
    "\n",
    "# Constitution des sets d'entrainement augmentés et de validation non augmenté\n",
    "train_dataset = ImagesToDataset(X_train, y_train, transform=base_transform.preproc(train=True))\n",
    "test_dataset = ImagesToDataset(X_test, y_test, transform=base_transform.preproc(train=False))\n",
    "\n",
    "# Loader des sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle et configuration de la pipeline d'entrainement\n",
    "\n",
    "# Instanciation du classificateur + déplacement sur le device\n",
    "model_classif = BrainCancerClassifier(\n",
    "    num_classes=1, \n",
    "    model_name=supervised_config['model']\n",
    ").to(DEVICE)\n",
    "# L'optimiseur ajuste les poids du modèle. Contient le learning_rate et les gradients.\n",
    "# On met un learning rate (lr) faible car fine-tuning \n",
    "# (on ne veut pas détruire ce que ResNet sait déjà).\n",
    "optimizer = optim.Adam(\n",
    "    model_classif.parameters(), \n",
    "    lr=supervised_config[\"supervised_learning_rate\"]\n",
    ")\n",
    "# On instancie la loss (sans poids car dataset équilibré)\n",
    "# criterion = nn.BCELoss() # Avec SIGMOID on prefere passer a logit\n",
    "# on a 50 images saines et 50 cancer du coup pos_weight ici vaut 1 mais en\n",
    "# supposant une répartition plus commune (plus de sain que non)\n",
    "# LOGIQUE METIER (personnelle): 3 pour 1\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3.0]).to(DEVICE))\n",
    "\n",
    "# Instanciation de la pipeline de training\n",
    "trainer = Trainer(\n",
    "    model_classif, \n",
    "    DEVICE, \n",
    "    criterion, \n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d'entraînement\n",
    "temp_best_f2 = 0.0\n",
    "temp_best_prauc = 0.0\n",
    "\n",
    "print(\"====== Entraînement Supervisé (100 images) ==========\")\n",
    "for epoch in range(supervised_config['supervised_n_epoch']):\n",
    "    # ================= ENTRAINEMENT ================\n",
    "    train_loss = trainer.train_epoch(train_loader) # on entraine sur le 80 images labellisées\n",
    "    \n",
    "    # ====================== EVAL =====================\n",
    "    results = trainer.eval_metrics(test_loader) # on evalue sur les 20 images restantes label\n",
    "    ece = trainer.calculate_ece(test_loader) # On estime la fiabilité de la confiance\n",
    "    print(f\"Epoch {epoch+1}/{supervised_config['supervised_n_epoch']} | Loss: {train_loss:.4f} | f2: {results[\"f2\"]:.4f} | ece: {ece:.4f}\")\n",
    "    \n",
    "    # ================= SAUVEGARDE INDIVIDUELLE DES MÉTRIQUES =============\n",
    "    temp_metrics ={\n",
    "            \"epoch\" : epoch+1,\n",
    "            \"train_loss\" : train_loss,\n",
    "            \"f2\" : results[\"f2\"],\n",
    "            \"precision\" : results[\"precision\"],\n",
    "            \"recall\":results[\"recall\"],\n",
    "            \"ece\":ece, # Fiabilité de la confiance du modèle\n",
    "            \"accuracy\": results[\"accuracy\"], # Exactitude\n",
    "            \"auc\": results[\"auc\"],# Capacité a séparer les labels\n",
    "            \"pr_auc\": results[\"pr_auc\"], # Précision sur les positifs\n",
    "        }\n",
    "    supervised_manager.log_metrics(temp_metrics)\n",
    "    \n",
    "    # ================ CHECKPOINT (SAVE SI MEILLEUR MODELE JUSQU'ICI) ===========\n",
    "    temp_f2 = results[\"f2\"]\n",
    "    temp_prauc = results['pr_auc']\n",
    "    # Double conditions pour valider le modèle: Le modèle cherche a s'améliorer (AUC) sans\n",
    "    # oublier la logique métier (f2)\n",
    "    if (temp_prauc > temp_best_prauc) or (temp_f2 > temp_best_f2):\n",
    "        if temp_f2 > (temp_best_f2*0.9): # le f2 ne doit pas être plus de 10% moins bon\n",
    "            temp_state = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model_classif.state_dict(), # ou plus rigoureux: trainer.model.state_dict()\n",
    "                'optimizer': optimizer.state_dict(),# ou plus rigoureux: trainer.optimizer.state_dict()\n",
    "                'f2': temp_f2,\n",
    "                'pr_auc': temp_prauc,\n",
    "                'config': supervised_config\n",
    "            }\n",
    "            \n",
    "            # réalise un checkpoint suivant la condition f2 (sauvegarde comme best ou pas)\n",
    "            supervised_manager.save_checkpoint(temp_state,is_best=True)\n",
    "            temp_best_f2 = max(temp_f2, temp_best_f2) # On garde le meilleur compromis \n",
    "            # QUE pour le checkpoint!\n",
    "            temp_best_prauc = temp_prauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sauvegarde du modele\n",
    "# Path.mkdir(SAVE_PATH/\"supervised\",exist_ok = True)\n",
    "# torch.save(model_classif.state_dict(), SAVE_PATH/\"supervised\"/\"model_supervised_baseline.pth\")\n",
    "\n",
    "# =========================================\n",
    "\n",
    "# ============== MEILLEUR MODELE POUR AFFICHAGE METRIQUES ===========\n",
    "model_classif.load_state_dict(torch.load(supervised_manager.ckpt_dir / \"best_model.pth\"))\n",
    "supervised_metrics = trainer.eval_metrics(test_loader)\n",
    "pd.DataFrame([supervised_metrics])\n",
    "# AJOUTER FONCTION POUR MATRICE DE CONFUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f07cb",
   "metadata": {},
   "source": [
    "La loss décroit assez vite pour fluctuer ensuite autour des derniers epochs tandis que f2 est stabilisé a 0.9184 mais peut varier ponctuellement. On voit que le meilleur couple est soit l'epoch 3 soit le 7 suivant l'intéret plutot sur f2 ou la loss mais le code a sauvegardé un modèle dont le f2 est de 0.918367 avec une précision de 1.0 et un recall de 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== NETTOYAGE ===============\n",
    "del (train_dataset, test_dataset, train_loader,\n",
    "    temp_state, train_loss, results, temp_metrics, supervised_manager, \n",
    "    temp_f2, temp_best_f2, temp_prauc, temp_best_prauc\n",
    ")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89008b46",
   "metadata": {},
   "source": [
    "<span style=\"color:purple;font-weight:bold\">Entrainement Semi Supervisée: Pseudo labelling sur les images inconnues</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cb117",
   "metadata": {},
   "source": [
    "Comme attendu pour un premier entrainement, les résultats sont assez médiocre.\n",
    "\n",
    "**On a donc vu dans un premier temps que la non supervision entrainait des résultats aléatoires dans un premier temps et que la supervision n'était pas non plus adaptée**\n",
    "\n",
    "C'est là qu'intervient la semi-supervision et on va pour cela utiliser le pseudo labelling. Son algorithme est le suivant:\n",
    "\n",
    "- Prédire sur les données non labellisées .\n",
    "- Sélectionner les prédictions où le modèle est le plus confiant (au-dessus d'un certain seuil).\n",
    "- Ajouter ces prédictions (images + pseudo-labels) au jeu d'entraînement étiqueté.\n",
    "- Ré-entraîner le modèle sur ce nouveau jeu de données augmenté.\n",
    "- Répéter !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gestionnaire de sauvegarde\n",
    "ssl_manager = SslManager(\n",
    "    EXPERIMENT_NAME,\n",
    "    root_path=SAVE_PATH,\n",
    "    extension_path=\"ssl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf62968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me^me pre traitement sur les données non labellisées (pas de split ni d'augment evidemment)\n",
    "Xu = sans_label_path\n",
    "yu = [-1]*len(sans_label_path)\n",
    "# dataset et loader\n",
    "udataset = ImagesToDataset(Xu, yu, transform=base_transform.preproc(train=False))\n",
    "uloader = DataLoader(udataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # Prédiction sur le set inconnu\n",
    "# print(\"=== Pseudo labelling sur les images inconnues ===\")\n",
    "# pseudo_X, pseudo_y = trainer.pseudo_labels(uloader)\n",
    "# print(f\"Nombre de pseudo-labels générés : {len(pseudo_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753aafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La mise en place globale du pseudo labelling\n",
    "counter = 0\n",
    "max_pseudo_iteration = 10\n",
    "reset = True # Si on repart d'une pipeline neuve (Cold start) ou pas (Continous Fine Tuning)\n",
    "# Cold start permet d'eviter l'accumulation d'erreurs et l'oubli (stacker les biais et \n",
    "# oublier les fortement labellisés) MAIS coût d'entrainement plus elevé\n",
    "\n",
    "# Garde fou pour éviter dérive\n",
    "temp_best_f2 = supervised_metrics['f2'] # On repart du f2 de la baseline (supervisée)\n",
    "temp_best_prauc = supervised_metrics['pr_auc'] # On repart de l'aucpr de la baseline (supervisée)\n",
    "best_trainer_state = copy.deepcopy(trainer.model.state_dict())\n",
    "best_pseudo_set = ([], [])\n",
    "stop = 0\n",
    "max_stop = 3\n",
    "ece = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91567c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_config = supervised_config | {\n",
    "    \"reset\":reset,\n",
    "    \"max_pseudo_iter\":max_pseudo_iteration,\n",
    "    \"ssl_learning_rate\":5e-5,\n",
    "    \"init_threshold\":0.70,\n",
    "    \"final_threshold\":0.95,\n",
    "    'ssl_n_epoch':N_EPOCH,\n",
    "}\n",
    "\n",
    "ssl_manager.save_config(ssl_config)\n",
    "\n",
    "# # décroissance du threshold, on assoupli le threshold a mesure des iterations\n",
    "# decay = np.linspace(\n",
    "#     ssl_config[\"init_threshold\"],\n",
    "#     ssl_config[\"init_threshold\"]-0.1,\n",
    "#     max_pseudo_iteration+1\n",
    "# )\n",
    "# On durci le ton a mesure des itérations\n",
    "decay = np.linspace(\n",
    "    ssl_config[\"init_threshold\"],\n",
    "    ssl_config[\"final_threshold\"],\n",
    "    max_pseudo_iteration+1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while counter <= max_pseudo_iteration:\n",
    "    # On s'assure que le threshold est bon\n",
    "    trainer.threshold = decay[counter]\n",
    "    \n",
    "    # ======== PRÉDICTION SUR SET INCONNU ET GET DES PSEUDO LABELS/PATHS =========\n",
    "    # IMPORTANT: AVANT D'ETRE ECRASE, ON RECOLTE PSEUDO_X ET Y! CE N'EST PAS ULOADER QUI DOIT\n",
    "    # ETRE MAJ MAIS TRAINER QUI SERA MODIFIE (NOUVEAU PSEUDO_X ET PSEUDO_Y) AVANT SON RESET.\n",
    "    # MODEL_CLASSIF ET OPTIMIZER DE LA PARTIE SUPERVISÉE ONT POUR SEULE UTILITÉ INFLUENCÉ TRAINER\n",
    "    print(f\"=== iter {counter} | pseudo labelling (seuil {decay[counter]:.4f}) ===\")\n",
    "    pseudo_X, pseudo_y = trainer.pseudo_labels(uloader)\n",
    "    print(f\"Pseudo-labels générés : {len(pseudo_X)}\")\n",
    "    \n",
    "    # ============= EMPECHE BOUCLE INUTIE ET DERIVE IMPORTANTE =================\n",
    "    if len(pseudo_X) == 0 or ece >= 0.6: # Ajout de l'ece pour eviter le biais de confirmation\n",
    "        print(\"Confiance rompue pour relancer l'entrainement\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # ========== MISE EN PLACE DU DATALOADER ================ \n",
    "    # (On NE STACK PAS les pseudo et on REPART TOUJOURS du jeu labellisé de base!)\n",
    "    new_X_train = X_train + [Path(x) for x in pseudo_X]\n",
    "    new_y_train = y_train + pseudo_y\n",
    "    \n",
    "    # dataset et loader, on applique des transformations et shuffle. Pour corser le travail et\n",
    "    # rendre l'entrainement plus efficace, on applique ici des transformations FORTES VS FAIBLE\n",
    "    # pour le train du supervisée\n",
    "    new_train_dataset = ImagesToDataset(\n",
    "        new_X_train,\n",
    "        new_y_train,\n",
    "        transform=base_transform.preproc(train=True,strong_augment=True)\n",
    "    )\n",
    "    new_train_loader = DataLoader(\n",
    "        new_train_dataset,\n",
    "        BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # ================ MISE EN PLACE DU TRAINER =========================\n",
    "    if reset:\n",
    "        # ============ COLD START ==============\n",
    "        # NEW START, on repart d'un nouveau modele et nouvel optimiseur (et entrainement)\n",
    "        # ========================= Cleaning ================\n",
    "        if 'new_trainer' in locals():\n",
    "            del new_model_classif, new_optimizer, new_trainer\n",
    "        gc.collect() # Libère la RAM CPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() # Libère la VRAM GPU\n",
    "        # =========================================\n",
    "        # CHARGEMENT DES POIDS DU MEILLEUR MODÈLE PRÉCÉDENT\n",
    "        new_model_classif = BrainCancerClassifier(\n",
    "            num_classes=1,\n",
    "            model_name=supervised_config['model']\n",
    "        ).to(DEVICE)\n",
    "        new_model_classif.load_state_dict(copy.deepcopy(best_trainer_state))\n",
    "        \n",
    "        new_optimizer = optim.Adam(\n",
    "            new_model_classif.parameters(), \n",
    "            lr=ssl_config[\"ssl_learning_rate\"]\n",
    "        )\n",
    "        # new_criterion = nn.BCELoss() # Avec SIGMOID on prefere passer a logit + label smoothing\n",
    "        new_trainer = Trainer(\n",
    "            new_model_classif, \n",
    "            DEVICE, \n",
    "            criterion, \n",
    "            new_optimizer, \n",
    "            threshold=decay[counter]\n",
    "        )\n",
    "    else:\n",
    "        # ============ CONTNOUS FINE TUNING ============\n",
    "        # ON GARDE LE MEME TRAINER, REDUCTION SEUIL + LEARNING_RATE pour ne pas détruire \n",
    "        # les poids déjà appris.\n",
    "        new_trainer = trainer\n",
    "        new_trainer.threshold = decay[counter]\n",
    "        # La boucle est obligatoire pour modifier le LR dans PyTorch\n",
    "        for param_group in new_trainer.optimizer.param_groups:\n",
    "            param_group['lr'] = ssl_config[\"ssl_learning_rate\"] / 10\n",
    "    \n",
    "    # =============== ENTRAINEMENT ====================================\n",
    "    IMPROVED_FLAG = False\n",
    "    print(f\"====== iter {counter} | seuil {decay[counter]:.4f} | {len(new_X_train)} images =======\")\n",
    "    for epoch in range(ssl_config['ssl_n_epoch']):\n",
    "        train_loss = new_trainer.train_epoch(new_train_loader) # le nouveau set de train\n",
    "        # ====================== EVAL =====================\n",
    "        results = new_trainer.eval_metrics(test_loader) # ON RESTE SUR LE MEME SET D'EVAL!\n",
    "        ece = new_trainer.calculate_ece(test_loader)\n",
    "        print(f\"Epoch {epoch+1}/{ssl_config['ssl_n_epoch']} | Loss: {train_loss:.4f} | f2: {results[\"f2\"]:.4f} | ece: {ece:.4f}\")\n",
    "        # =============== CHECKPOINT =====================================\n",
    "        temp_metrics = {\n",
    "            \"epoch\":epoch+1,\n",
    "            \"iteration\":counter,\n",
    "            \"threshold\":decay[counter],\n",
    "            \"n_pseudo\":len(pseudo_X),\n",
    "            \"f2\":results['f2'],\n",
    "            \"train_loss\":train_loss,\n",
    "            \"ece\":ece, # Fiabilité de la confiance du modèle\n",
    "            \"accuracy\": results[\"accuracy\"], # Exactitude\n",
    "            \"auc\": results[\"auc\"],# Capacité a séparer les labels\n",
    "            \"pr_auc\": results[\"pr_auc\"], # Précision sur les positifs\n",
    "        }\n",
    "        ssl_manager.log_metrics(temp_metrics)\n",
    "        \n",
    "        temp_f2 = results['f2']\n",
    "        temp_prauc = results['pr_auc']\n",
    "        \n",
    "        if (temp_prauc > temp_best_prauc) or (temp_f2 > temp_best_f2):\n",
    "            if temp_f2 >= (temp_best_f2 * 0.9): # Garde-fou de 10%\n",
    "                \n",
    "                # On sauvegarde l'état du modèle et les pseudos qui ont fonctionné\n",
    "                best_trainer_state = copy.deepcopy(new_trainer.model.state_dict())\n",
    "                \n",
    "                temp_best_f2 = max(temp_f2, temp_best_f2)# On garde le meilleur compromis \n",
    "                # QUE pour le checkpoint!\n",
    "                temp_best_prauc = temp_prauc\n",
    "                IMPROVED_FLAG = True\n",
    "                \n",
    "                temp_state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    \"counter\":counter,\n",
    "                    # new_model_classif.state_dict() == new_trainer.model.state_dict() \n",
    "                    # donc on peut raccourcir ici car pointent au même objet en mémoire\n",
    "                    'state_dict': new_model_classif.state_dict(), \n",
    "                    # new_optimizer.state_dict(), si pas de cold start: plante car n'existe pas\n",
    "                    'optimizer': new_trainer.optimizer.state_dict(),\n",
    "                    'f2': temp_f2,\n",
    "                    'pr_auc': temp_prauc,\n",
    "                    'config': ssl_config\n",
    "                }\n",
    "                ssl_manager.save_checkpoint(temp_state, is_best=True)\n",
    "                ssl_manager.save_weak_labels(pseudo_X, pseudo_y)\n",
    "                \n",
    "    if not IMPROVED_FLAG: # On a fait la boucle d'entrainement mais pas d'amélioration sur l'iteration\n",
    "        # ============= CAS LAMBDA =============\n",
    "        # Rollback : on recharge les poids du meilleur modèle dans le trainer actuel\n",
    "        new_trainer.model.load_state_dict(best_trainer_state)\n",
    "        stop+=1\n",
    "    else:\n",
    "        stop = 0 # on reinitialise le compteur de stagnation\n",
    "    if stop >= max_stop:\n",
    "        print('Arrêt prématuré, plus de progression')\n",
    "        break\n",
    "    \n",
    "    trainer = new_trainer\n",
    "    counter+=1\n",
    "    \n",
    "    # ========================= Cleaning ================\n",
    "    # Nettoyage de fin d'itération\n",
    "    del new_train_loader\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() # Libère la VRAM GPU\n",
    "# ========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2e4f3",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold\">Le nombre de pseudo label augmente mais f2 et la loss ne changent pas ==> biais de confirmation? On va vérifier si le modèle n'est pas dans un état de persuarsion car sa confiance est proche de 1 sans gros entrainement. De plus le jeu étant très petit notamment le coté labellisé, il est etonnant qu'on passe d'un modèle non supervisé incapable de distinguer les labels à un cas de certitude</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89d3b8",
   "metadata": {},
   "source": [
    "Pour faire une vérification de l'état (après shutdown du kernel) il faut remettre en place l'environnement:\n",
    "\n",
    "2. Initialiser le manager (SslManager) et charger la configuration du projet (config.yaml)\n",
    "3. Reconstruire le checkpoint (ou seulement le modele):\n",
    "    - Instancier le modèle (models.ResNet)\n",
    "    - Instancier l'optimiseur (torch.optim.Adam)\n",
    "    - Charger et injecter les poids et l'etat (manager.load_checkpoint)\n",
    "4. Instancier le trainer (Trainer)\n",
    "5. Recharger si pas encore fait:\n",
    "    - Le loader sur l'echantillon de validation des labels forts\n",
    "    - Le loader du jeu inconnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_manager = SslManager(experiment_name=EXPERIMENT_NAME,root_path=SAVE_PATH/\"ssl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4174ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# # Au lieu de yaml.safe_load(f)\n",
    "# with open(test_manager.config_path, 'r') as f:\n",
    "#     config = yaml.load(f, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b862bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_epoch = test_manager.load_checkpoint(model_classif,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f339fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score de test\n",
    "test_results = trainer.eval_metrics(test_loader)\n",
    "print(f\"F2-Score vérifié : {test_results['f2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence des pseudo labels\n",
    "df_pseudo = pd.read_parquet(ssl_manager.labels_path)\n",
    "print(df_pseudo['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notebooks.utils.analyze_ssl import analyze_confidence\n",
    "from notebooks.utils.plotting.make_model_plots import plot_confidence\n",
    "# analyze_confidence(trainer,uloader)\n",
    "plot_confidence(\n",
    "    probas=results['raw_data']['probs'],\n",
    "    threshold_range=list(decay),\n",
    "    stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.calculate_ece(results['raw_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e6aae",
   "metadata": {},
   "source": [
    "ece = 0.6922483702185118 ==> Très mauvais, le modèle est en plein biais de confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e288b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livrable-p7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
